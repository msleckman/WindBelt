---
title: "logistic_regression"
author: "Hanna Buechi"
date: "2/28/2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

###Load packages (incl. for sentiment analysis)
```{r}

library(tidyverse)
library(googledrive)
library(purrr)
library(readr)
library(stringr)
library(gsubfn)
library(devtools)
library(dplyr)
library(tidytext)
library(broom)
library(data.table)
library(ggplot2)
library(dotwhisker)
library(jtools)
library(sjPlot)
library(jtools)
library(ggeffects)
library(pscl)
library(car)
library(InformationValue)
library(boot)

ventyx_df_google_Sen <- read_csv("ventyx_df_google_Sen_022219.csv")

## Make sure Impact is coded correctly
# I don't have the updated CSV that Margaux put on the Bren G: drive
ventyx_df_google_Sen <- ventyx_df_google_Sen %>% 
  mutate(H_L_W = ifelse(lr_tif > "0", "Low", "High"))

```

###Logistic regression

####Organize factors and levels for categorical variables
```{r organize_for_regressions}

ventyx_df_google_Sen$H_L_W <- as.factor(ventyx_df_google_Sen$H_L_W)

ventyx_df_google_Sen$H_L_W <- relevel(ventyx_df_google_Sen$H_L_W, ref = "High")

ventyx_df_google_Sen$PopDensity <- as.numeric(ventyx_df_google_Sen$PopDensity)

ventyx_df_google_Sen$Household_ <- as.numeric(ventyx_df_google_Sen$Household_)

ventyx_df_google_Sen$View_Score <- as.numeric(ventyx_df_google_Sen$View_Score)

ventyx_df_google_Sen$Sign_Google <- as.factor(ventyx_df_google_Sen$Sign_Google)

ventyx_df_google_Sen$OnlyCancel <- as.factor(ventyx_df_google_Sen$OnlyCancel)

ventyx_df_google_Sen$State <- as.factor(ventyx_df_google_Sen$State)

## Set reference state to Texas because I don't have the state abbrev. column
ventyx_df_google_Sen$State <- relevel(ventyx_df_google_Sen$State, ref = "Texas")


### adding normalization to df 
# 
# ventyx_df_NU_google_Sen_norm <- ventyx_df_NU_google_Sen %>% 
#   select(-starts_with("X")) %>% 
#   mutate(Capacity_2 = normalize(Capacity),
#          View_Score_2 = normalize(View_Score),
#          Google_Sentiment_2 = normalize(Google_Sentiment),
#          NU_Sentiment_2 = normalize(NU_Sentiment),
#          PopDensity_mi_2 = normalize(PopDensity_mi),
#          Household_MedianIncome_2 = normalize(Household_MedianIncome),
#          members_env_2 = normalize(members_env)) 
  
```

###Finalize data for regression
####Make publicity NAs = 0
```{r finalize_ventyx_for_regression}

# Make NA scores 0
ventyx_df_google_Sen <- ventyx_df_google_Sen %>% 
  mutate(Google_Sentiment = ifelse(is.na(Google_Sentiment),0,Google_Sentiment)) %>% 
  mutate(Canceled = ifelse(OnlyCancel == "Yes",1,0))

ventyx_df_google_Sen <- ventyx_df_google_Sen %>% 
  filter(Capacity >= 0) %>% 
  filter(TimelineDa > 0) %>% 
  filter(!lr_tif < 0) %>% 
  filter(!View_Score < 0)

### For descriptive stats
#write.csv(ventyx_df_NU_google_Sen, "~/Desktop/ventyx_df_NU_google_Sen_01.18.19.csv")

```


```{r prep}

## For some kind of visualization?
renamed_variables <- c(View_Score = "View Score",
                        Google_Sentiment = "Google News Publicity score",
                        NU_Sentiment = "Nexis Uni Publicity score",
                        PopDensity_mi = "Population Density per m2",
                        Household_MedianIncome = "Household Median Income",
                        Capacity = "Capacity",
                        H_L_WLow = "High vs. low impact area"
                        # H_L_W*NU_Sentiment = "site vs. sentiment interaction"
                       )

## Subset data
ventyx_Operating <- ventyx_df_google_Sen %>% 
  filter(OnlyCancel == "No" & Artificial == "No" & OperatingD == "No")

ventyx_Operating_Canceled <- ventyx_df_google_Sen %>% 
  filter(Artificial == "No" & OperatingD == "No")

ventyx_Cancelled <- ventyx_df_google_Sen %>% 
  filter(OnlyCancel == "Yes" & OperatingD == "No" & Artificial == "No")

Ventyx_Operating_NoZeros <- ventyx_df_google_Sen %>% 
  filter(OnlyCancel == "No" & Artificial == "No" & OperatingD == "No") %>% 
  filter(Google_Sentiment != 0)

Ventyx_Operating_Canceled_NoZeros <- ventyx_df_google_Sen %>% 
  filter(Artificial == "No" & OperatingD == "No") %>% 
  filter(Google_Sentiment != 0) %>% 
  filter(State != "Arkansas")

#ventyx_Operating_Canceled$OnlyCancel <- relevel(ventyx_Operating_Canceled$OnlyCancel, ref = "No")
# write_csv(ventyx_df_google_Sen, "G:/Data/VENTYX_DATASET/ventyx_df_google_Sen_022219_2.csv")

```


###LOGISTIC REGRESSION
```{r log_regression}

#For the purposes of this regression, we first want to subset our data into a section that we used to train the model, and a section for testing the predicted probabilities later on.
train <- ventyx_Operating_Canceled[1:800,]
test <- ventyx_Operating_Canceled[801:871,]

#To test the reversal of values if we switch "High" impact areas to "Low" and vice verse
test_reversed <- test %>% 
  mutate(H_L_W = ifelse(H_L_W == "High", "Low","High"))

#Next, we run the logistic regression
logistic_reg_all <- glm(Canceled ~ TimelineDa + View_Score + Google_Sentiment + PopDensity + Household_ + Capacity + H_L_W + State + members_env + Google_Sentiment*H_L_W, family = binomial, data = train)

#View model results
summary(logistic_reg_all) #coefficients represent log odds
exp(coef(logistic_reg_all)) #exponentiated coefficients

#Run anova to compare null deviance vs. residual deviance. The greater the difference the better.
anova(logistic_reg_all, test="Chisq")

#Diagnostic plots
glm.diag.plots(logistic_reg_all)

#To view the logistic model equivalent of R-squared
pR2(logistic_reg_all)

#Check for multicollinearity
vif(logistic_reg_all) #low multicollinearity

#Now we predict the probability of the test projects being canceled
pred_probs <- predict(logistic_reg_all, newdata=test, type='response', se.fit = TRUE)
pred_probs_df <- data.frame(test, pred_probs$fit, pred_probs$se.fit)
pred_probs_df <- pred_probs_df %>% 
  rename(Probability = pred_probs.fit) %>% 
  rename(Publicity = Google_Sentiment)

#Now predict probabilities for reversed values
pred_probs_reversed <- predict(logistic_reg_all, newdata=test_reversed, type='response', se.fit = TRUE)
pred_probs_df_reversed <- data.frame(test, pred_probs_reversed$fit, pred_probs_reversed$se.fit)
pred_probs_df_reversed <- pred_probs_df_reversed %>% 
  rename(Probability = pred_probs_reversed.fit) %>% 
  rename(Publicity = Google_Sentiment)

#Probability means
mean(pred_probs_df$Probability)
mean(pred_probs_df_reversed$pred_probs_reversed.fit)

# pred_low <- pred_probs_df %>% 
#   filter(H_L_W == "Low")
# pred_high <- pred_probs_df %>% 
#   filter(H_L_W == "High")
# mean(pred_low$Probability)
# mean(pred_high$Probability)

#To evaluate the misclassification of predicted cancelations and actual cancelations -- essentially, how accurate are the predictions?
optCutOff <- optimalCutoff(test$Canceled, pred_probs$fit)
misClassError(test$Canceled, pred_probs$fit, threshold = optCutOff) #~14% misclassification error, so overall pretty accurate

#Plot ROC, which traces the percentage of true positives accurately predicted by the model as the prediction probability cutoff is lowered from 1 to 0.
plotROC(test$Canceled, pred_probs$fit) #the graph has a steep curve, which indicated a good quality model

#Measure concordance, which measures how well high probability scores match up with cancelation values, and vice versa.
Concordance(test$Canceled, pred_probs$fit) #a concordance of ~0.9 is a high quality model

```

###Calculate probability of cancellation of other projects

```{r}

ventyx_Truncated <- ventyx_df_google_Sen %>% 
  filter(Artificial == "Yes")

# same workflow as Alex's predictions above

# Timelines ARE included

pred_probs_trunc <- predict(logistic_reg_all, newdata=ventyx_Truncated, type='response', se.fit = TRUE)
pred_probs_trunc_df <- data.frame(ventyx_Truncated, pred_probs_trunc$fit, pred_probs_trunc$se.fit)
pred_probs_trunc_df <- pred_probs_trunc_df %>% 
  rename(Probability = pred_probs_trunc.fit) %>% 
  rename(Publicity = Google_Sentiment)

```

