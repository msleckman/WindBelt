---
title: "descriptive stats wrangling"
author: "Margaux Sleckman"
date: "January 6, 2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r packages}


#install.packages("pdftools", "devtools")
library(pdftools)
library(tm)
# library(tm.plugin.lexisnexis)
library(devtools)
# install.packages("tidytext")
library(tidytext)
library(broom)
# install.packages("tidyverse")
library(data.table)
library(tidyverse)
library(purrr)
library(lubridate)
library(knitr)

library(googledrive)

library(effsize)

```

To pull ventyx dataset from google drive directly

```{r google_drive}

#########
# Pull ventyx dataset
# 
# drive_auth()
# Windbelt_Data_id <- "1lvoVfdeUjft6sFtXwZ7OZo5ly3B7VZ9g?ogsrc=32"
# 
# Windbelt_Data_gfolder <- googledrive::drive_ls(googledrive::as_id(Windbelt_Data_id))
# ventyx_dataset <- Windbelt_Data_gfolder$name[Windbelt_Data_gfolder$name == "ventyx_converted_11_27_2018_PopDensity_Income_Viewshed_lowhighimpact_doc_names.csv"]
# length(ventyx_dataset)
# 
# local_folder <- "G:/Data/VENTYX_DATASET/"
# 
# drive_read(Windbelt_Data_gfolder[1], fun = read_csv, fun_args = list())
#             
# 
# length(ventyx_dataset))
# file_downloader <- function(templates_dribble, local_folder){
#   # download all pdfs
#   for (i in 1:nrow(templates_dribble)){
#     drive_download(as_id(templates_dribble$id[[i]]), 
#                    file.path(local_folder, templates_dribble$name[[i]]),
#                    overwrite = TRUE) #check if overwrite is neede here
#   }
# }
# 
# file_downloader(ventyx_dataset, local_folder)
# 
# View(team_drive_find(pattern = "ventyx_converted_11_27_2018_popdensity_income_viewshed_lowhighimpact_doc_names.csv"))

#################


```

Read in ventyx csv 
```{r ventyx_dataset}


#Change when working from G drive
home_folder<-"C:/Users/Cristina/Documents/Bren/GP/"
#home_folder <- "G:/Data/VENTYX_DATASET/"


# Old Ventyx dataset - to archive
# Ventyx_dataset <- read_csv(file = "G:/Data/VENTYX_DATASET/ventyx_converted_11_27_2018_PopDensity_Income_Viewshed_lowhighimpact_doc_names.csv") %>% 
#   filter(!is.na(lr_tif))

Ventyx_dataset<- read_csv(file = paste0(home_folder, "ventyx_df_with_NU_google_Sentiments_01.18.19.csv")) %>% filter(!is.na(lr_tif)) %>% filter(!is.na(View_Score))
Ventyx_dataset$Household_MedianIncome <- as.numeric(Ventyx_dataset$Household_MedianIncome)


View(Ventyx_dataset)

dim(Ventyx_dataset)

```

Total number of projects recorded (minus all NAs, negative capacity, 0 timeline days): 896

```{r phase_date}

# split data of latest date to get earliest date/oldest date: 
Ventyx_dataset<-separate(Ventyx_dataset,
                         PhaseHistory,
                         into = c("PhaseHistory", 'PhaseHistory_date'), sep = ":")

class(Ventyx_dataset$PhaseHistory_date)

Ventyx_dataset$PhaseHistory_date <- as.Date(Ventyx_dataset$PhaseHistory_date, "%m/%d/%Y")

class(Ventyx_dataset$PhaseHistory_date)

min(Ventyx_dataset$PhaseHistory_date)
max(Ventyx_dataset$PhaseHistory_date)

# median(Ventyx_dataset$PhaseHistory_date)

```
Earliest date: 2012-01-01
Latest date: 2018-10-09


Stats on farms in low-impact/high-impact areas
```{r low-high_impact, results = 'asis'}

### low-high impact:

length(Ventyx_dataset$lr_tif[Ventyx_dataset$lr_tif == 0])
length(Ventyx_dataset$lr_tif[Ventyx_dataset$lr_tif == 1])

# Low impact area by state:
ventyx_lowimpact <- Ventyx_dataset %>% 
  filter(H_L_W == "Low") %>% 
  group_by(State) %>% 
  summarise(count=n())

sum(ventyx_lowimpact$count) # verifying all low impact areas are somewhere


ventyx_nonlowimpact <- Ventyx_dataset %>% 
  filter(H_L_W == "High") %>% 
  group_by(State) %>% 
  summarise(count=n())

View(ventyx_nonlowimpact)

# Ventyx_dataset_lowhighimpact_totals <- Ventyx_dataset %>%
#   select(ProjectName, ProjectDeveloper, State, lr_tif) %>%
#   group_by(State) %>% 
#   summarise(count= n()) %>% 
#   summarise(low_impact = sum(Ventyx_dataset$lr_tif == 1))
#   
#  View(Ventyx_dataset_lowhighimpact_totals)
 
 ##Summary tables:

# By State:
 
 ByState <- Ventyx_dataset %>%
   select(ProjectName, NU_Sentiment, Google_Sentiment, ProjectDeveloper, State, H_L_W, Capacity, TimelineDays) %>% 
   group_by(State) %>% 
   mutate(LowImpact = sum(H_L_W == "Low")) %>% 
   mutate(NonLowImpact = sum (H_L_W == "High")) %>% 
   mutate(TotalProjects = sum(H_L_W == "Low" | H_L_W == "High")) %>%
   #mutate(AvgNexisSentiment = mean(NU_Sentiment)) %>% 
   mutate(AvgGoogleSentiment = mean(Google_Sentiment)) %>% 
   mutate(AvgCapacity = mean(Capacity)) %>% 
   mutate(AvgTimeline = mean(TimelineDays)) %>% 
   select(State,LowImpact, NonLowImpact, TotalProjects, AvgGoogleSentiment, AvgCapacity, AvgTimeline) %>% 
   # Need to add column for sentiment
   unique()
 

View(ByState)

kable(ByState)


## By Impact:

ByImpact <- Ventyx_dataset %>%
   select(ProjectName, ProjectDeveloper, State, H_L_W, Capacity, TimelineDays, Household_MedianIncome, View_Score, NU_Sentiment, Google_Sentiment, PopDensity_mi) %>% 
  group_by(H_L_W) %>% 
  mutate(TotalProjects = sum(H_L_W == "Low" | H_L_W == "High")) %>%
  mutate(AvgTimeline = mean(TimelineDays)) %>%
  #mutate(AvgNexisSentiment = mean(NU_Sentiment)) %>% 
  mutate(AvgGoogleSentiment = mean(Google_Sentiment)) %>%
  #mutate(MaxNexisSentiment = max(NU_Sentiment)) %>% 
  #mutate(MinNexisSentiment = min(NU_Sentiment)) %>% 
  mutate(MaxGoogleSentiment = max(Google_Sentiment)) %>% 
  mutate(MinGoogleSentiment = min(Google_Sentiment)) %>% 
  mutate(AvgCapacity = mean(Capacity)) %>% 
  mutate(AvgMedianIncome = mean(Household_MedianIncome)) %>% 
  mutate(Avg_Viewscore = mean(View_Score)) %>% 
  mutate(Avg_PopDensity = mean(PopDensity_mi)) %>% 
  select(TotalProjects, AvgTimeline,
         AvgGoogleSentiment, MaxGoogleSentiment, MinGoogleSentiment, AvgCapacity,  AvgMedianIncome, Avg_Viewscore, Avg_PopDensity) %>% 
   unique()

#Box and whisker plot by impact for sentiment?

View(ByImpact)

kable(ByImpact)

print(ByImpact)


NUSen_nozeros <- Ventyx_dataset %>% 
  filter(Ventyx_dataset$NU_Sentiment != 0)
GoogleSen_nozeros <- Ventyx_dataset %>% 
  filter(Ventyx_dataset$Google_Sentiment !=0)

GoogleSen_fake <- GoogleSen_nozeros %>% 
  mutate(fake_sentiment = ifelse(H_L_W=="High", Google_Sentiment-1.5,
         ifelse(H_L_W=="Low", Google_Sentiment, NA)))

dim(NUSen_nozeros)
dim(GoogleSen_nozeros)


ImpactNUSentimentPlot <- ggplot(NUSen_nozeros, aes(x=as.factor(H_L_W), y = NU_Sentiment))+
  geom_boxplot(fill="slateblue", alpha = 0.2)+
  xlab("H_L_W")

ImpactGoogleSentimentPlot <- ggplot(GoogleSen_nozeros, aes(x=as.factor(H_L_W), y = Google_Sentiment))+
  geom_boxplot(alpha = 0.2, linetype = "dashed", fill = NA)+
  xlab("Impact")+
  ylab("Publicity Score")+
  theme_classic()+
  theme(axis.title.x=element_blank(), text = element_text(size = 20), axis.text.y = element_blank(), axis.ticks.y = element_blank())+
  guides(fill=FALSE)+
  scale_x_discrete(labels = c("Other", "Low"))+
  geom_boxplot(data = GoogleSen_fake, aes(x=as.factor(H_L_W), y = fake_sentiment, fill = H_L_W))
  

ImpactGoogleSentimentPlot

mean(Ventyx_dataset$TimelineDays)

 

```

```{r}

# By Sentiment:

Ventyx_dataset <- Ventyx_dataset %>% 
mutate(NU_class =
           ifelse(NU_Sentiment>0, "Positive",
                  ifelse(NU_Sentiment==0, "Neutral/No Publicity",
                         "Negative"))) %>% 
mutate(Google_class =
           ifelse(Google_Sentiment>0, "Positive",
                  ifelse(Google_Sentiment==0, "Neutral/No Publicity",
                         "Negative")))

ByNUSentiment <- Ventyx_dataset %>% 
  group_by(NU_class) %>% 
  mutate(TotalProjects = sum(H_L_W == "Low" | H_L_W == "High")) %>%
  mutate(AvgTimeline = mean(TimelineDays)) %>%
  mutate(LowImpact = sum(H_L_W == "Low")) %>% 
  mutate(HighImpact = sum(H_L_W=="High")) %>%
  mutate(AvgCapacity = mean(Capacity)) %>% 
  mutate(AvgMedianIncome = mean(Household_MedianIncome)) %>% 
  mutate(Avg_Viewscore = mean(View_Score)) %>% 
  select(TotalProjects, AvgTimeline, LowImpact, HighImpact, AvgCapacity,  AvgMedianIncome, Avg_Viewscore) %>% 
   unique()


ByGoogleSentiment <- Ventyx_dataset %>% 
  group_by(Google_class) %>% 
  mutate(TotalProjects = sum(H_L_W == "Low" | H_L_W == "High")) %>%
  mutate(AvgTimeline = mean(TimelineDays)) %>%
  mutate(LowImpact = sum(H_L_W == "Low")) %>% 
  mutate(HighImpact = sum(H_L_W=="High")) %>%
  mutate(AvgCapacity = mean(Capacity)) %>% 
  mutate(AvgMedianIncome = mean(Household_MedianIncome)) %>% 
  mutate(Avg_Viewscore = mean(View_Score)) %>% 
  select(TotalProjects, AvgTimeline, LowImpact, HighImpact, AvgCapacity,  AvgMedianIncome, Avg_Viewscore) %>% 
   unique()

kable(ByNUSentiment)
kable(ByGoogleSentiment)
  

```


Stats on developers
```{r developer}

## developer stats:
# ProjDev_nonlowimpact <- Ventyx_dataset %>% 
#   filter(lr_tif == 0) %>% 
#   group_by(ProjectDeveloper) %>% 
#   summarise(count=n()) %>% 
#   sort(decreasing = T)
#   
# ProjDev_lowimpact <- Ventyx_dataset %>% 
#   filter(lr_tif == 1) %>% 
#   group_by(ProjectDeveloper) %>% 
#   summarise(count=n()) 
#   
# View(ProjDev_lowimpact)
# View(ProjDev_nonlowimpact)
# 
# ProjDev_lowhighimpact_totals <- Ventyx_dataset %>%
#   select(ProjectDeveloper, lr_tif) %>%
#   group_by(ProjectDeveloper) %>% 
#   summarise(count= n())

# View(ProjDev_lowhighimpact_totals)

##Summary by developer

 Impact_by_developer <- Ventyx_dataset %>%
   select(ProjectName, ProjectDeveloper, State, lr_tif) %>% 
   group_by(ProjectDeveloper) %>% 
   mutate(low_impact = sum(lr_tif == 1)) %>% 
   mutate(nonlow_impact = sum (lr_tif == 0)) %>% 
   mutate(total = sum(lr_tif == 1 | lr_tif == 0)) %>% 
   select(ProjectDeveloper,low_impact, nonlow_impact, total) %>% 
   unique() %>% 
  arrange(-total)
 

View(Impact_by_developer)

kable(Impact_by_developer)

```

```{r}

sen_delay_plot <- ggplot(Ventyx_dataset, aes(x = TimelineDays, y = Google_Sentiment, color = H_L_W)) +
  geom_point()

sen_delay_plot



```



```{r}

#t test between sentiment in high and sentiment in low
# is there a difference (two direction)

## Test assumptions

# sen_hist <- ggplot(Ventyx_dataset, aes(Google_Sentiment)) +
#   geom_histogram(bins=15) +
#   facet_wrap(~H_L_W, scale = "free")
# 
# sen_hist

#NOPE, having zeros makes it weird distribution (does this matter? should we test with or without 0s?)

Ventyx_nozeros <- Ventyx_dataset %>% 
  filter(Ventyx_dataset$Google_Sentiment!=0)

dim(Ventyx_nozeros)

summary_nozeros <- Ventyx_nozeros %>% 
  group_by(H_L_W) %>% 
  summarise(no_rows=length(H_L_W))

sen_hist <- ggplot(Ventyx_nozeros, aes(Google_Sentiment)) +
  geom_histogram(bins=15) +
  facet_wrap(~H_L_W, scale = "free")

sen_hist

## Make a prettier histogram

sen_hist_comb <- ggplot(Ventyx_nozeros, aes(Google_Sentiment)) +
  geom_histogram(alpha = 0.5, bins=15, fill = "#6fa4dc") +
  xlab("Publicity Score")+
  ylab("Frequency")+
  theme_classic()+
  theme(text=element_text(size = 20))
  

sen_hist_comb

xlab("Impact")+
  ylab("Google Sentiment")+
  theme_classic()+
  theme(axis.title.x=element_blank(), text = element_text(size = 20))+
  guides(fill=FALSE)+
  scale_x_discrete(labels = c("Other", "Low"))

sen_qq <- ggplot(Ventyx_nozeros, aes(sample = Google_Sentiment)) +
  geom_qq() +
  facet_wrap(~H_L_W, scale = "free")

sen_qq

sen_ftest <- var.test(Google_Sentiment ~ H_L_W, data = Ventyx_nozeros)

#Ratio of variances is not 1 (unequal variances)

sen_ttest <- t.test(Google_Sentiment ~ H_L_W, data = Ventyx_nozeros)

sen_ttest
#Did not differ significantly (p = 0.58)

effect_sen <- cohen.d(Google_Sentiment ~ H_L_W, data = Ventyx_nozeros)


```

```{r}

# t test between delay in high and delay in low
# is there a difference (two direction)

delay_hist <- ggplot(Ventyx_dataset, aes(TimelineDays)) +
  geom_histogram(bins=15) +
  facet_wrap(~H_L_W, scale = "free")

delay_hist

delay_qq <- ggplot(Ventyx_dataset, aes(sample = TimelineDays)) +
  geom_qq() +
  facet_wrap(~H_L_W, scale = "free")

delay_qq

##Not normal but lots of sample points

delay_ftest <- var.test(TimelineDays ~ H_L_W, data = Ventyx_dataset)

#Ratio of variances is not 1 (unequal variances)

delay_ttest <- t.test(TimelineDays ~ H_L_W, data = Ventyx_dataset)

delay_ttest



# p = 0.99

```



stats on average timeline 
```{r timelines}

# ## timeline stats
# 
# mean(Ventyx_dataset$TimelineDays)
# min(Ventyx_dataset$TimelineDays)
# max(Ventyx_dataset$TimelineDays)
# 
# # low impact
# all_ventyx_lowimpact <- Ventyx_dataset %>% 
#   filter(lr_tif == 1)
# mean(all_ventyx_lowimpact$TimelineDays)
# max(all_ventyx_lowimpact$TimelineDays)
# min(all_ventyx_lowimpact$TimelineDays)
# 
# all_ventyx_nonlowimpact <- Ventyx_dataset %>% 
#   filter(lr_tif == 0)
# 
# mean(all_ventyx_nonlowimpact$TimelineDays)
# max(all_ventyx_nonlowimpact$TimelineDays)
# min(all_ventyx_nonlowimpact$TimelineDays)


```

```{r}

#Normalize pop density, median income, viewscore, capacity, timeline days, Google Sentiment

ventyx_normal <- Ventyx_dataset %>% 
  mutate(PopDensity_mi_norm = ((((PopDensity_mi - min(PopDensity_mi)) * (100 - 1)) / (max(PopDensity_mi) - min(PopDensity_mi)))) + 1) %>% 
  mutate(Household_MedianIncome_norm = ((((Household_MedianIncome - min(Household_MedianIncome)) * (100 - 1)) / (max(Household_MedianIncome) - min(Household_MedianIncome)))) + 1) %>% 
  mutate(View_Score_norm = ((((View_Score - min(View_Score)) * (100 - 1)) / (max(View_Score) - min(View_Score)))) + 1) %>% 
  mutate(Capacity_norm = ((((Capacity - min(Capacity)) * (100 - 1)) / (max(Capacity) - min(Capacity)))) + 1) %>% 
  mutate(TimelineDays_norm = ((((TimelineDays - min(TimelineDays)) * (100 - 1)) / (max(TimelineDays) - min(TimelineDays)))) + 1) %>% 
  mutate(Google_Sentiment_norm = ((((Google_Sentiment - min(Google_Sentiment)) * (100 - 1)) / (max(Google_Sentiment) - min(Google_Sentiment)))) + 1)
  
  
         
View(ventyx_normal)


```

